version: '3.9'

# HaberNexus v9.0 - Complete Docker Compose Configuration
# Includes: Django App, PostgreSQL, Redis, Celery, Caddy, Cloudflare Tunnel
# Deployment: Cloudflare Tunnel + Caddy (Automatic HTTPS)

services:
  # ============================================================================
  # REVERSE PROXY & TUNNEL
  # ============================================================================

  # Caddy - Reverse Proxy with Automatic HTTPS
  caddy:
    build:
      context: .
      dockerfile: caddy/Dockerfile
    container_name: habernexus_caddy
    restart: unless-stopped
    
    ports:
      - "80:80"
      - "443:443"
    
    volumes:
      - ./caddy/Caddyfile:/etc/caddy/Caddyfile:ro
      - caddy_data:/data
      - caddy_config:/config
    
    environment:
      - CLOUDFLARE_API_TOKEN=${CLOUDFLARE_API_TOKEN}
    
    networks:
      - habernexus_network
    
    depends_on:
      - app
    
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:80/health"]
      interval: 30s
      timeout: 5s
      retries: 3
      start_period: 10s
    
    labels:
      com.example.description: "Caddy Reverse Proxy with Automatic HTTPS"
    
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  # Cloudflare Tunnel - Secure Connection
  cloudflared:
    image: cloudflare/cloudflared:latest
    container_name: habernexus_cloudflared
    restart: unless-stopped
    
    command: tunnel run
    
    volumes:
      - ./cloudflared/config.yml:/etc/cloudflared/config.yml:ro
      - ~/.cloudflared:/root/.cloudflared:ro
    
    environment:
      - TUNNEL_TOKEN=${CLOUDFLARE_TUNNEL_TOKEN}
    
    networks:
      - habernexus_network
    
    depends_on:
      - caddy
    
    healthcheck:
      test: ["CMD", "cloudflared", "tunnel", "info"]
      interval: 30s
      timeout: 5s
      retries: 3
      start_period: 10s
    
    labels:
      com.example.description: "Cloudflare Tunnel for Secure Connection"
    
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  # ============================================================================
  # CORE SERVICES
  # ============================================================================

  # PostgreSQL - Primary Database
  postgres:
    image: postgres:16-alpine
    container_name: habernexus_postgres
    restart: unless-stopped
    
    environment:
      POSTGRES_DB: "${DB_NAME:-habernexus}"
      POSTGRES_USER: "${DB_USER:-habernexus_user}"
      POSTGRES_PASSWORD: "${DB_PASSWORD:-change-me-in-production}"
      POSTGRES_INITDB_ARGS: "-c shared_buffers=256MB -c max_connections=200"
      TZ: "Europe/Istanbul"
    
    volumes:
      - postgres_data:/var/lib/postgresql/data
    
    networks:
      - habernexus_network
    
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${DB_USER:-habernexus_user}"]
      interval: 10s
      timeout: 5s
      retries: 5
    
    labels:
      com.example.description: "PostgreSQL Database for HaberNexus"
    
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  # Redis - Cache and Message Broker
  redis:
    image: redis:7-alpine
    container_name: habernexus_redis
    restart: unless-stopped
    
    command: >
      redis-server
      --appendonly yes
      --maxmemory 512mb
      --maxmemory-policy allkeys-lru
    
    volumes:
      - redis_data:/data
    
    networks:
      - habernexus_network
    
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5
    
    labels:
      com.example.description: "Redis Cache and Message Broker"
    
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  # ============================================================================
  # DJANGO APPLICATION
  # ============================================================================

  # Django Application Server
  app:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: habernexus_app
    restart: unless-stopped
    
    command: >
      sh -c "python manage.py migrate &&
             python manage.py collectstatic --noinput &&
             gunicorn -w 4 -b 0.0.0.0:8000 habernexus_config.wsgi:application"
    
    expose:
      - "8000"
    
    environment:
      - DEBUG=${DEBUG:-False}
      - SECRET_KEY=${SECRET_KEY}
      - ALLOWED_HOSTS=${ALLOWED_HOSTS:-localhost,127.0.0.1}
      - DATABASE_URL=postgresql://${DB_USER:-habernexus_user}:${DB_PASSWORD:-change-me}@postgres:5432/${DB_NAME:-habernexus}
      - REDIS_URL=redis://redis:6379/0
      - CELERY_BROKER_URL=redis://redis:6379/0
      - CELERY_RESULT_BACKEND=redis://redis:6379/0
      - ADMIN_EMAIL=${ADMIN_EMAIL}
      - ADMIN_USERNAME=${ADMIN_USERNAME}
      - ADMIN_PASSWORD=${ADMIN_PASSWORD}
      - TZ=Europe/Istanbul
    
    volumes:
      - ./app:/app
      - static_files:/app/staticfiles
      - media_files:/app/media
    
    networks:
      - habernexus_network
    
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
    
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 5s
      retries: 3
      start_period: 30s
    
    labels:
      com.example.description: "Django Application Server"
    
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  # ============================================================================
  # BACKGROUND TASKS
  # ============================================================================

  # Celery Worker
  celery:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: habernexus_celery
    restart: unless-stopped
    
    command: celery -A habernexus_config worker -l info --concurrency=4
    
    environment:
      - DEBUG=${DEBUG:-False}
      - SECRET_KEY=${SECRET_KEY}
      - ALLOWED_HOSTS=${ALLOWED_HOSTS:-localhost,127.0.0.1}
      - DATABASE_URL=postgresql://${DB_USER:-habernexus_user}:${DB_PASSWORD:-change-me}@postgres:5432/${DB_NAME:-habernexus}
      - REDIS_URL=redis://redis:6379/0
      - CELERY_BROKER_URL=redis://redis:6379/0
      - CELERY_RESULT_BACKEND=redis://redis:6379/0
      - TZ=Europe/Istanbul
    
    volumes:
      - ./app:/app
    
    networks:
      - habernexus_network
    
    depends_on:
      - app
      - redis
      - postgres
    
    labels:
      com.example.description: "Celery Worker for Background Tasks"
    
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  # Celery Beat - Task Scheduler
  celery_beat:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: habernexus_celery_beat
    restart: unless-stopped
    
    command: celery -A habernexus_config beat -l info --scheduler django_celery_beat.schedulers:DatabaseScheduler
    
    environment:
      - DEBUG=${DEBUG:-False}
      - SECRET_KEY=${SECRET_KEY}
      - ALLOWED_HOSTS=${ALLOWED_HOSTS:-localhost,127.0.0.1}
      - DATABASE_URL=postgresql://${DB_USER:-habernexus_user}:${DB_PASSWORD:-change-me}@postgres:5432/${DB_NAME:-habernexus}
      - REDIS_URL=redis://redis:6379/0
      - CELERY_BROKER_URL=redis://redis:6379/0
      - CELERY_RESULT_BACKEND=redis://redis:6379/0
      - TZ=Europe/Istanbul
    
    volumes:
      - ./app:/app
    
    networks:
      - habernexus_network
    
    depends_on:
      - app
      - redis
      - postgres
    
    labels:
      com.example.description: "Celery Beat Task Scheduler"
    
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  # Flower - Celery Monitoring
  flower:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: habernexus_flower
    restart: unless-stopped
    
    command: celery -A habernexus_config flower --port=5555 --broker=redis://redis:6379/0
    
    expose:
      - "5555"
    
    environment:
      - CELERY_BROKER_URL=redis://redis:6379/0
      - CELERY_RESULT_BACKEND=redis://redis:6379/0
      - TZ=Europe/Istanbul
    
    networks:
      - habernexus_network
    
    depends_on:
      - celery
      - redis
    
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:5555"]
      interval: 30s
      timeout: 5s
      retries: 3
      start_period: 10s
    
    labels:
      com.example.description: "Flower Celery Monitoring Tool"
    
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

# ============================================================================
# NETWORKS
# ============================================================================

networks:
  habernexus_network:
    driver: bridge
    ipam:
      config:
        - subnet: 172.20.0.0/16

# ============================================================================
# VOLUMES
# ============================================================================

volumes:
  postgres_data:
    driver: local
  redis_data:
    driver: local
  caddy_data:
    driver: local
  caddy_config:
    driver: local
  static_files:
    driver: local
  media_files:
    driver: local
